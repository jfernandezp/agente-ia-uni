import streamlit as st
import boto3
from langchain_aws import ChatBedrock  # Cambiado de BedrockChat a ChatBedrock
from langchain_core.memory import ConversationBufferMemory  # Cambiado de langchain_core
from langchain_core.chains import ConversationChain  # Cambiado de langchain_core
from langchain_core.prompts import PromptTemplate
from botocore.exceptions import ClientError
import sys

def initialize_deepseek_chatbot(system_instructions=None):
    """
    Inicializa un chatbot con DeepSeek en AWS Bedrock usando LangChain.
    
    Args:
        system_instructions (str): Instrucciones del sistema para el chatbot
    
    Returns:
        ConversationChain: Cadena de conversaci贸n configurada
    """
    
    # Configuraci贸n de AWS Bedrock
    AWS_BEDROCK_MODEL_ID = "deepseek.mistral.mistral-large-2402-v1:0"
    AWS_REGION = "us-east-1"
    
    # Instrucciones por defecto si no se proporcionan
    if system_instructions is None:
        system_instructions = """Eres un asistente de IA 煤til y educado llamado Asistente USIL. 
Responde preguntas sobre la Universidad San Ignacio de Loyola (USIL) y San Ignacio University (SIU).
S茅 preciso, conciso y amable en tus respuestas.
Si no sabes algo, adm铆telo honestamente.
Usa espa帽ol para todas las respuestas."""
    
    try:
        # Inicializar cliente de Bedrock
        bedrock_client = boto3.client(
            service_name="bedrock-runtime",
            region_name=AWS_REGION
        )
        
        # Configurar el modelo de chat de Bedrock - ACTUALIZADO
        llm = ChatBedrock(
            client=bedrock_client,
            model_id=AWS_BEDROCK_MODEL_ID,
            model_kwargs={
                "temperature": 0.7,
                "max_tokens": 1000,
                "top_p": 0.9,
            },
            streaming=False
        )
        
        # Crear template del prompt con instrucciones del sistema
        prompt_template = PromptTemplate(
            input_variables=["history", "input"],
            template=f"""{system_instructions}

Historial de conversaci贸n:
{{history}}

Usuario: {{input}}
Asistente:"""
        )
        
        # Configurar memoria para la conversaci贸n - ACTUALIZADO
        memory = ConversationBufferMemory(
            memory_key="history",
            return_messages=True,
            human_prefix="Usuario",
            ai_prefix="Asistente"
        )
        
        # Crear cadena de conversaci贸n - ACTUALIZADO
        conversation_chain = ConversationChain(
            llm=llm,
            memory=memory,
            prompt=prompt_template,
            verbose=False
        )
        
        return conversation_chain
        
    except ClientError as e:
        st.error(f"Error de AWS Bedrock: {e.response['Error']['Message']}")
        return None
    except Exception as e:
        exc_type, exc_obj, tb = sys.exc_info()
        line_number = tb.tb_lineno
        st.error(f"Error al inicializar el chatbot: {str(e)} - L铆nea: {line_number}")
        return None

def create_chat_interface(conversation_chain, title="Chatbot USIL", greeting=None):
    """
    Crea una interfaz de chat en Streamlit.
    
    Args:
        conversation_chain (ConversationChain): Cadena de conversaci贸n inicializada
        title (str): T铆tulo del chat
        greeting (str): Mensaje de bienvenida inicial
    """
    
    if greeting is None:
        greeting = "隆Hola! Soy tu asistente de USIL. 驴En qu茅 puedo ayudarte hoy?"
    
    # Configurar t铆tulo
    st.title(f" {title}")
    
    # Inicializar historial de chat en session_state
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": greeting}]
    
    if "conversation" not in st.session_state:
        st.session_state.conversation = conversation_chain
    
    # Mostrar historial de mensajes
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # Input del usuario
    if prompt := st.chat_input("Escribe tu pregunta aqu铆..."):
        # A帽adir mensaje del usuario
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # Obtener respuesta del chatbot
        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                try:
                    # Usar la cadena de conversaci贸n - ACTUALIZADO
                    response = st.session_state.conversation.run(input=prompt)
                    
                    # Limpiar respuesta si es necesario
                    response = response.strip()
                    
                    # Mostrar respuesta
                    st.write(response)
                    
                    # A帽adir al historial
                    st.session_state.messages.append(
                        {"role": "assistant", "content": response}
                    )
                    
                except Exception as e:
                    error_msg = f"Lo siento, hubo un error al procesar tu pregunta: {str(e)}"
                    st.write(error_msg)
                    st.session_state.messages.append(
                        {"role": "assistant", "content": error_msg}
                    )
    
    # Sidebar con opciones adicionales
    with st.sidebar:
        st.header("锔 Configuraci贸n del Chat")
        
        # Bot贸n para limpiar conversaci贸n
        if st.button("Ч Limpiar Conversaci贸n"):
            st.session_state.messages = [{"role": "assistant", "content": greeting}]
            if st.session_state.conversation:
                st.session_state.conversation.memory.clear()
            st.rerun()
        
        # Mostrar informaci贸n del modelo
        st.subheader("癸 Informaci贸n")
        st.write(f"**Modelo:** DeepSeek")
        st.write(f"**Plataforma:** AWS Bedrock")

# Versi贸n alternativa si tienes problemas con langchain-aws
def initialize_deepseek_chatbot_alternative(system_instructions=None):
    """
    Versi贸n alternativa usando directamente boto3 si hay problemas con LangChain.
    """
    
    AWS_BEDROCK_MODEL_ID = "deepseek.mistral.mistral-large-2402-v1:0"
    
    if system_instructions is None:
        system_instructions = """Eres un asistente de IA 煤til y educado. Responde en espa帽ol."""
    
    # Crear una clase simple para simular el comportamiento de LangChain
    class SimpleDeepSeekChat:
        def __init__(self, system_instructions):
            self.system_instructions = system_instructions
            self.memory = []
            self.client = boto3.client("bedrock-runtime", region_name="us-east-1")
        
        def run(self, input_text):
            try:
                # Formatear el prompt con historial
                history_text = "\n".join([f"{msg['role']}: {msg['content']}" 
                                        for msg in self.memory[-5:]])  # ltimos 5 mensajes
                
                prompt = f"""{self.system_instructions}

Historial previo:
{history_text}

Usuario: {input_text}
Asistente:"""
                
                body = {
                    "prompt": prompt,
                    "max_tokens": 1000,
                    "temperature": 0.7,
                    "top_p": 0.9
                }
                
                response = self.client.invoke_model(
                    modelId=AWS_BEDROCK_MODEL_ID,
                    body=json.dumps(body)
                )
                
                response_body = json.loads(response["body"].read())
                response_text = response_body["choices"][0]["text"].strip()
                
                # Guardar en memoria
                self.memory.append({"role": "Usuario", "content": input_text})
                self.memory.append({"role": "Asistente", "content": response_text})
                
                return response_text
                
            except Exception as e:
                return f"Error: {str(e)}"
        
        def clear_memory(self):
            self.memory = []
    
    return SimpleDeepSeekChat(system_instructions)

# Funci贸n principal actualizada
def main():
    """
    Ejemplo de implementaci贸n principal.
    """
    st.set_page_config(
        page_title="Chatbot USIL - DeepSeek",
        page_icon="",
        layout="wide"
    )
    
    st.markdown("<h1 style='text-align: center; color: #2E86C1;'> Asistente Virtual USIL</h1>", 
                unsafe_allow_html=True)
    
    # Opci贸n para elegir m茅todo
    method = st.sidebar.selectbox(
        "Selecciona el m茅todo:",
        ["LangChain (Recomendado)", "Directo Boto3"]
    )
    
    if method == "LangChain (Recomendado)":
        try:
            # Intentar con LangChain actualizado
            chatbot = initialize_deepseek_chatbot()
            if chatbot:
                create_chat_interface(
                    conversation_chain=chatbot,
                    title="Asistente USIL (LangChain)",
                    greeting="隆Hola! Soy tu asistente, 驴en qu茅 puedo ayudarte?"
                )
            else:
                st.error("No se pudo inicializar con LangChain. Probando m茅todo alternativo...")
                # Fallback al m茅todo alternativo
                chatbot_alt = initialize_deepseek_chatbot_alternative()
                create_simple_interface(chatbot_alt)
        except Exception as e:
            st.error(f"Error con LangChain: {e}")
            st.info("Intentando m茅todo alternativo...")
            chatbot_alt = initialize_deepseek_chatbot_alternative()
            create_simple_interface(chatbot_alt)
    
    else:
        # M茅todo directo con Boto3
        chatbot_alt = initialize_deepseek_chatbot_alternative()
        create_simple_interface(chatbot_alt)

def create_simple_interface(chatbot, title="Chatbot USIL"):
    """Interfaz simple para el m茅todo alternativo."""
    
    st.title(f" {title}")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    if prompt := st.chat_input("Escribe tu mensaje..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                response = chatbot.run(prompt)
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
    
    if st.sidebar.button("Limpiar chat"):
        st.session_state.messages = []
        chatbot.clear_memory()
        st.rerun()

if __name__ == "__main__":
    import json  # Aseg煤rate de importar json si usas el m茅todo alternativo
    main()